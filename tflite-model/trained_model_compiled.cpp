/* Generated by Edge Impulse
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */
// Generated on: 04.02.2023 09:20:25

#include <stdio.h>
#include <stdlib.h>
#include "edge-impulse-sdk/tensorflow/lite/c/builtin_op_data.h"
#include "edge-impulse-sdk/tensorflow/lite/c/common.h"
#include "edge-impulse-sdk/tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "edge-impulse-sdk/porting/ei_classifier_porting.h"
#include "edge-impulse-sdk/tensorflow/lite/micro/kernels/softmax.h"
#include "edge-impulse-sdk/tensorflow/lite/micro/kernels/kernel_util.h"

#if EI_CLASSIFIER_PRINT_STATE
#if defined(__cplusplus) && EI_C_LINKAGE == 1
extern "C" {
    extern void ei_printf(const char *format, ...);
}
#else
extern void ei_printf(const char *format, ...);
#endif
#endif

#if defined __GNUC__
#define ALIGN(X) __attribute__((aligned(X)))
#elif defined _MSC_VER
#define ALIGN(X) __declspec(align(X))
#elif defined __TASKING__
#define ALIGN(X) __align(X)
#endif

#ifndef EI_MAX_SCRATCH_BUFFER_COUNT
#define EI_MAX_SCRATCH_BUFFER_COUNT 4
#endif // EI_MAX_SCRATCH_BUFFER_COUNT

#ifndef EI_MAX_OVERFLOW_BUFFER_COUNT
#define EI_MAX_OVERFLOW_BUFFER_COUNT 10
#endif // EI_MAX_OVERFLOW_BUFFER_COUNT

using namespace tflite;
using namespace tflite::ops;
using namespace tflite::ops::micro;

namespace {

constexpr int kTensorArenaSize = 288;

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX)
#pragma Bss(".tensor_arena")
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#pragma Bss()
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) __attribute__((section(".tensor_arena")));
#else
#define EI_CLASSIFIER_ALLOCATION_HEAP 1
uint8_t* tensor_arena = NULL;
#endif

static uint8_t* tensor_boundary;
static uint8_t* current_location;

template <int SZ, class T> struct TfArray {
  int sz; T elem[SZ];
};
enum used_operators_e {
  OP_FULLY_CONNECTED, OP_SOFTMAX,  OP_LAST
};
struct TensorInfo_t { // subset of TfLiteTensor used for initialization from constant memory
  TfLiteAllocationType allocation_type;
  TfLiteType type;
  void* data;
  TfLiteIntArray* dims;
  size_t bytes;
  TfLiteQuantization quantization;
};
struct NodeInfo_t { // subset of TfLiteNode used for initialization from constant memory
  struct TfLiteIntArray* inputs;
  struct TfLiteIntArray* outputs;
  void* builtin_data;
  used_operators_e used_op_index;
};

struct SoftmaxNodeInfo_t { // subset of TfLiteNode used for initialization from constant memory
  struct TfLiteIntArray* inputs;
  struct TfLiteIntArray* outputs;
  const TfLiteSoftmaxParams* params;
};

struct FullyConnectedNodeInfo_t { // subset of TfLiteNode used for initialization from constant memory
  struct TfLiteIntArray* inputs;
  struct TfLiteIntArray* outputs;
  const TfLiteFullyConnectedParams* params;
};

TfLiteContext ctx{};

const TfArray<2, int> tensor_dimension0 = { 2, { 1,54 } };
const TfArray<1, float> quant0_scale = { 1, { 0.10220763087272644, } };
const TfArray<1, int> quant0_zero = { 1, { -47 } };
const TfLiteAffineQuantization quant0 = { (TfLiteFloatArray*)&quant0_scale, (TfLiteIntArray*)&quant0_zero, 0 };
const ALIGN(16) int8_t tensor_data1[30*54] = {
  -28, -14, -7, 40, -15, 3, 15, 4, -15, 39, 33, -4, 54, -10, -22, 28, -18, 20, 16, 59, -29, -4, 42, 37, -17, 25, -2, -2, 33, 44, 21, 21, -20, -13, 20, -36, 30, 27, -19, -15, 21, 18, -1, -14, 31, 8, -14, -3, 14, 7, 50, -10, 15, 16,
  -6, 25, 2, -7, 11, 14, 12, -19, -19, -35, -24, -6, 14, 18, -32, -10, 1, -31, 7, -30, 43, 4, -18, 15, -23, 6, -30, -25, -1, -42, -43, -46, -15, -4, 30, 32, 20, -16, 45, -46, 17, -17, 9, -9, 0, -35, -22, -40, -24, 20, -13, -39, 11, -7,
  -28, 68, 7, 9, -33, -44, -26, -46, 9, -10, -29, 32, 47, -7, 25, 49, -33, -37, -16, 67, 10, -1, 10, -36, 38, 1, 21, 38, 52, 61, 69, 93, 77, 84, -21, 28, 10, 45, 5, 21, 11, -26, -8, -18, -1, 20, 29, -68, -25, -28, 34, -22, -61, 0,
  -50, 41, 18, -21, -29, 39, 47, 36, 39, -14, 25, 25, 92, 114, 37, 29, 9, 36, -39, -25, 16, 16, -21, 28, 46, 12, 32, 5, 42, 31, 30, -31, 9, 73, -27, -18, -58, -57, 10, -62, -13, 41, 48, 42, 33, 65, 27, 62, 48, 69, 27, 26, -32, 41,
  -9, -44, 21, 13, -36, 15, 1, -40, -9, -19, -14, -40, 3, -35, -31, -19, -6, 8, 4, -13, 3, -10, 10, 22, 14, -4, -29, -5, -31, -34, -16, 10, 16, -2, -40, 32, 17, -10, -39, 22, -33, 20, -28, -39, 0, 23, -43, 19, -5, -6, 9, 29, -1, 10,
  64, 43, -17, 20, 12, 16, 0, 11, 40, 10, 28, -19, 31, 51, -30, 8, -32, -36, 33, -23, 11, -24, 25, 38, -5, 34, 14, 55, 41, 20, 25, -48, -13, -12, -30, -43, 6, -44, 6, -9, -26, -44, 24, -5, 9, -20, -16, 37, -46, -34, -41, -35, 18, 40,
  -17, -3, -15, -30, 32, -9, 7, 15, -20, 3, 36, 47, -5, -3, 39, 26, 35, 3, 1, -64, 13, 7, 24, 17, 44, 0, 22, 19, 0, -19, 15, 0, 45, 80, 15, 14, -63, -22, 16, -15, 45, 12, 2, 21, 59, 21, 19, 13, 29, 2, 18, 59, 44, 21,
  -6, -2, -19, 40, 28, 32, -22, 14, -10, 7, 1, 24, 12, 29, -12, 37, 17, 27, 14, 26, -47, 27, 1, -25, -21, 15, 15, -26, 27, 26, 34, 49, 19, 4, 30, 4, 23, 55, 4, 31, 25, 15, 31, 50, 43, -8, -17, 40, 24, -13, 39, -5, 36, -47,
  7, -61, -8, 27, -16, -24, -49, -25, -23, -8, -48, -38, -33, -12, -40, -22, -5, -35, -6, -75, -38, 47, 53, 36, 18, -45, -13, -64, -72, -70, -60, -62, -29, -31, -49, -22, -51, -92, 29, -47, 20, 35, 58, 68, -5, 49, -2, 40, 68, -13, 60, 17, 38, 22,
  19, -54, -18, 55, 19, -41, -11, -16, -26, -6, -49, 1, 27, -24, -63, 13, 0, 46, 7, 40, -43, -8, -21, 16, -32, -31, -5, -30, -19, -13, -90, -6, -21, -57, 16, -11, 83, 56, -29, 74, 1, 3, -4, -6, 35, 52, 48, 34, -8, -8, -9, 30, 39, 37,
  -35, -31, -14, 3, 8, -43, 20, -26, 1, 3, -43, -22, -33, 27, -11, -32, -28, -45, 14, -17, 47, 12, -3, -20, -21, 1, -7, 37, 34, -37, 22, 11, -15, 23, -25, 31, 25, 1, 27, 3, -22, -29, -41, -18, 27, -15, -25, -40, -33, -28, -29, 14, 6, 18,
  21, -22, -2, 24, -1, -34, 29, -25, 0, -29, 8, -28, 23, -3, -11, -23, 32, 24, 19, -18, -39, -46, -17, 27, 25, 23, -20, -7, -38, -37, -14, -12, 4, 22, 11, 4, 14, -60, 46, -46, -18, -26, -3, -25, 18, 15, 17, 19, 8, 32, 33, -16, -9, 35,
  3, -23, -9, -4, -2, -34, 23, -19, -35, 13, -42, -11, -27, 23, -7, 9, -24, 12, 1, -27, 33, -41, 19, 1, -29, -26, 23, -12, 0, -9, -17, -11, -6, 31, -3, -19, 19, 16, 14, 17, -39, -43, -16, -37, 21, 7, -39, 7, 1, -20, 17, -17, -22, 5,
  -7, -18, 22, 0, 8, -5, 17, -41, 8, -6, 0, -10, 7, -42, -15, -3, -26, 12, -5, 8, -39, -8, 7, 17, 23, -36, -42, -16, 15, -34, -3, -31, -6, 33, -15, 42, 14, 26, 27, -36, -11, -19, -15, 0, 4, -46, 23, -20, -4, -1, -28, 18, -6, 29,
  -28, -15, -24, 34, 21, 9, -11, 4, -27, -28, -1, -12, -13, 9, 18, 11, 24, 36, -13, -1, 3, -16, 24, -12, 11, -25, -8, -28, 27, -32, 3, 29, 28, 18, 7, -16, -12, 28, -2, 4, -42, -17, -15, -9, 15, -13, -39, -9, 23, 3, 4, 4, -14, -6,
  -22, -16, 1, 19, -14, -26, 6, -34, -23, 4, -33, -27, -76, -52, -75, -28, -52, 9, 6, 24, -93, 25, 30, 20, -3, 27, 17, 14, 14, -40, -13, 29, -11, -16, 16, 40, -19, 112, -53, 10, 34, 45, -19, 5, 2, -32, -14, -52, 2, -65, 24, 26, -21, -38,
  -45, -21, 14, -24, -14, -9, -2, -7, -25, 44, 39, -1, -83, 7, -23, 8, 19, -43, 14, -71, -6, -17, 33, -10, 16, 18, 49, 25, 2, 0, 3, 2, 47, 54, -3, 13, -40, -82, 8, -18, -1, 29, 42, -5, 32, -4, 55, 31, 47, -17, -8, 25, 27, 33,
  -27, -14, -20, 19, -6, 20, -7, -29, -3, -33, -17, -39, -18, -22, -16, -16, 35, 32, 26, 20, 42, -43, -3, 0, 24, 6, -3, -41, -34, -32, 31, 22, 2, 24, 34, 50, 22, -26, 3, -35, 15, 0, 19, 0, -25, 13, -4, 18, -47, 4, 18, -9, 14, 29,
  -31, -13, 20, 38, 51, 12, -7, 49, 52, -7, 16, 21, -26, -23, -19, -11, -14, -6, -17, 32, 10, 24, 42, 21, 33, -28, 8, -33, 0, -29, 10, 54, 28, -9, -18, -6, 37, 69, -24, 50, 55, 24, -22, 63, 9, 13, 31, -10, 44, -7, -5, 52, 37, -14,
  28, -83, -15, 30, -16, 49, 50, 20, -11, 22, 24, 15, -13, 38, 5, 35, 37, 6, 78, -36, -50, 13, 12, 55, 25, -16, 14, -19, 25, 14, 18, -31, 1, -50, 13, 45, -28, -127, 10, -12, -36, 3, -16, 10, -7, 16, -23, -28, -53, -33, -10, -3, -15, 13,
  -31, -29, -3, -21, -33, 1, 28, 28, 29, -11, 28, 15, -23, -22, 31, -33, -18, -23, -18, -46, -29, -41, 5, 9, 22, -29, 26, -4, 17, 8, -10, 22, 7, 29, -32, -2, 2, 7, 4, 28, -15, 16, -24, -23, 9, -41, 25, -12, -2, 5, 16, -38, 14, 18,
  -1, 5, 8, 28, 21, 20, 11, 22, -39, -31, -23, 11, 8, 10, -46, -2, -31, -14, -27, 22, 35, -31, -40, -36, 14, 23, -22, -17, -4, -37, 6, -3, -19, -4, -25, 46, -10, 27, -12, 11, -3, 17, -19, 16, -35, 7, -38, -11, -15, -4, -19, 20, -25, -20,
  -57, -10, 13, 13, -23, -5, -4, -50, -31, 9, -28, -2, -44, -31, -42, -36, -10, -48, -13, -8, 36, -18, -22, -1, -15, -7, 4, 14, -23, -10, -10, -24, -41, -33, -1, -39, 79, 11, 6, 61, -32, 36, 17, 16, -9, 31, 36, -32, 37, -15, -42, 6, -14, -3,
  34, 12, 2, -6, 47, 47, 27, 91, 53, 64, 31, 3, 44, -10, 71, 7, 71, 32, 36, -52, 22, 19, -6, 10, 6, 17, 33, -11, 17, -15, 44, -14, 19, -19, -17, -28, -55, 2, 24, -40, 5, 41, -2, 46, -2, -26, 16, 10, 4, 41, -8, 28, 31, 3,
  20, 52, 3, 3, -21, 6, 21, -6, -8, 9, -13, -24, 26, 12, -11, 13, -16, -27, 58, 60, -22, 15, -42, -39, -8, -12, 23, -1, 1, 12, 32, -33, 12, -24, -1, 8, 48, 8, 3, 58, -2, -36, 42, -12, -39, -20, -2, -10, -15, -13, 8, -8, 58, 33,
  -22, -15, 11, 22, 2, -16, -28, 6, -27, 28, -26, 16, 22, -1, -17, -36, 9, 14, 27, -14, 48, -39, -19, -22, 2, -9, -9, -31, 16, -22, -41, 27, -10, -10, -17, 7, 22, -7, 30, -27, 0, -26, 8, 17, 19, -32, -31, -2, -30, -12, 11, -14, 14, -2,
  38, 51, -22, 12, -36, 11, -6, -32, -33, -47, -2, -9, 10, 4, 10, 1, -21, -43, 32, 64, 9, -29, -34, 17, 2, -2, 41, 58, -4, 47, 37, 10, -6, -3, -14, -29, 55, -81, 26, -3, -34, -32, 6, -22, -29, 19, -8, -22, -19, 22, 6, 0, 19, 28,
  26, -37, -15, -24, -43, -31, 12, 5, -26, -15, -11, -22, -22, -46, -45, -41, -40, -36, 5, 7, 46, 1, -4, -39, 3, -34, 1, 22, -28, 34, 15, 30, 4, -7, -13, 39, 2, -13, 3, -30, 13, 19, -37, -19, -29, -9, -40, 22, 32, 12, 2, -13, 25, 24,
  6, 37, 15, -3, -7, -21, -48, -29, -16, -10, 4, 6, 3, 20, 9, 52, 49, 35, 14, -11, 5, 24, 21, 12, 0, -1, 11, -55, 16, 23, 28, 9, 29, 6, 10, -12, -24, 3, 24, -11, 35, 34, 25, 11, 23, -34, 5, -5, 60, 44, 38, -5, 2, -22,
  -6, 31, -13, -15, -26, 20, -11, 15, -12, 18, -3, -45, -41, -21, -13, -39, -31, -5, 15, -44, 28, 22, -20, -10, 13, 7, -41, -25, 8, -32, 14, 13, 16, 20, -32, -3, -47, 32, 15, -26, -26, -4, 18, 17, -33, -12, -9, -34, -10, -44, 15, 11, -22, 8,
};
const TfArray<2, int> tensor_dimension1 = { 2, { 30,54 } };
const TfArray<1, float> quant1_scale = { 1, { 0.0072235148400068283, } };
const TfArray<1, int> quant1_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant1 = { (TfLiteFloatArray*)&quant1_scale, (TfLiteIntArray*)&quant1_zero, 0 };
const ALIGN(16) int32_t tensor_data2[30] = { 75, -122, 52, 396, -57, -206, 500, 255, 798, 36, 58, -24, -112, -110, -64, 190, 325, -110, 406, -289, -46, -68, -41, 209, -532, 48, -389, -35, 47, -149, };
const TfArray<1, int> tensor_dimension2 = { 1, { 30 } };
const TfArray<1, float> quant2_scale = { 1, { 0.00073829834582284093, } };
const TfArray<1, int> quant2_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant2 = { (TfLiteFloatArray*)&quant2_scale, (TfLiteIntArray*)&quant2_zero, 0 };
const ALIGN(16) int8_t tensor_data3[10*30] = {
  -34, -8, 7, 8, 31, -32, -12, 1, -41, -41, -20, -31, 33, 29, -12, -7, -43, 0, -18, -1, 27, -24, -41, -8, -28, -37, 34, -28, -41, -24,
  -42, 10, 8, 52, 15, 31, 23, -26, -5, -36, 17, -33, 1, -9, -31, -42, -14, 28, 17, -44, 16, 51, 14, 29, -9, 51, 2, 45, -2, 35,
  -44, 24, 5, -75, 21, -9, 15, -26, 34, 26, -31, -26, 7, -47, 14, -21, -17, 37, -46, -19, 37, -37, -6, 20, 21, 15, -30, -33, -7, 31,
  -21, -9, 41, 34, 13, -2, 81, 39, 114, -32, 51, 9, -4, -31, -14, 98, 48, 19, 33, -52, -19, 31, -7, 70, -15, -34, -83, 40, 19, 12,
  34, -6, -98, -112, -51, 64, -53, 29, -37, 127, -6, -55, -43, 9, -8, -9, -23, -50, 65, 35, 13, 36, 46, 47, 82, -28, 19, -37, 5, -10,
  21, 29, -31, -3, -36, -18, 1, -15, 43, -40, -56, 35, -41, 14, -22, 29, -42, -10, -39, 24, 30, 17, -15, -1, -35, -3, -45, -48, -48, -34,
  24, -17, 49, 100, 27, -36, 47, 23, 93, 19, -24, 22, -53, -4, 1, 19, 43, -12, 22, -42, 43, 8, -61, 37, -66, 20, -34, -51, 38, 15,
  -36, 51, -16, -36, 30, -25, -1, -52, 74, 52, 39, 34, 5, -1, -9, 8, 9, 4, -10, 12, 35, 23, 46, -27, -51, 38, -3, 15, -35, 33,
  -39, 22, -2, 16, 33, -12, 29, -49, -14, -44, 14, 25, 32, 38, -6, 13, -38, 32, -3, -8, -45, 7, 7, -9, 19, -15, -9, 27, 27, -13,
  -22, 17, 14, 57, -40, 52, 64, -24, 107, -40, -6, 41, -47, 0, -32, -7, 77, 35, -42, 58, 11, 0, -51, 73, -6, 1, 7, -42, 22, -29,
};
const TfArray<2, int> tensor_dimension3 = { 2, { 10,30 } };
const TfArray<1, float> quant3_scale = { 1, { 0.008408878929913044, } };
const TfArray<1, int> quant3_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant3 = { (TfLiteFloatArray*)&quant3_scale, (TfLiteIntArray*)&quant3_zero, 0 };
const ALIGN(16) int32_t tensor_data4[10] = { -45, 4, -48, 193, 23, -39, 128, 15, -55, -80, };
const TfArray<1, int> tensor_dimension4 = { 1, { 10 } };
const TfArray<1, float> quant4_scale = { 1, { 0.0012572892010211945, } };
const TfArray<1, int> quant4_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant4 = { (TfLiteFloatArray*)&quant4_scale, (TfLiteIntArray*)&quant4_zero, 0 };
const ALIGN(16) int8_t tensor_data5[4*10] = {
  -34, 3, 24, 48, -12, -28, -80, 29, 22, -1,
  45, -17, 65, 40, -42, 21, 84, -55, 43, 61,
  -82, -124, -56, 113, 32, 39, 77, 1, 23, -123,
  -75, 65, 55, -72, 76, -2, -73, -88, -78, 127,
};
const TfArray<2, int> tensor_dimension5 = { 2, { 4,10 } };
const TfArray<1, float> quant5_scale = { 1, { 0.0072064818814396858, } };
const TfArray<1, int> quant5_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant5 = { (TfLiteFloatArray*)&quant5_scale, (TfLiteIntArray*)&quant5_zero, 0 };
const ALIGN(16) int32_t tensor_data6[4] = { -74, -97, 151, 68, };
const TfArray<1, int> tensor_dimension6 = { 1, { 4 } };
const TfArray<1, float> quant6_scale = { 1, { 0.0017295477446168661, } };
const TfArray<1, int> quant6_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant6 = { (TfLiteFloatArray*)&quant6_scale, (TfLiteIntArray*)&quant6_zero, 0 };
const TfArray<2, int> tensor_dimension7 = { 2, { 1,30 } };
const TfArray<1, float> quant7_scale = { 1, { 0.14951923489570618, } };
const TfArray<1, int> quant7_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant7 = { (TfLiteFloatArray*)&quant7_scale, (TfLiteIntArray*)&quant7_zero, 0 };
const TfArray<2, int> tensor_dimension8 = { 2, { 1,10 } };
const TfArray<1, float> quant8_scale = { 1, { 0.23999890685081482, } };
const TfArray<1, int> quant8_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant8 = { (TfLiteFloatArray*)&quant8_scale, (TfLiteIntArray*)&quant8_zero, 0 };
const TfArray<2, int> tensor_dimension9 = { 2, { 1,4 } };
const TfArray<1, float> quant9_scale = { 1, { 0.28170770406723022, } };
const TfArray<1, int> quant9_zero = { 1, { 32 } };
const TfLiteAffineQuantization quant9 = { (TfLiteFloatArray*)&quant9_scale, (TfLiteIntArray*)&quant9_zero, 0 };
const TfArray<2, int> tensor_dimension10 = { 2, { 1,4 } };
const TfArray<1, float> quant10_scale = { 1, { 0.00390625, } };
const TfArray<1, int> quant10_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant10 = { (TfLiteFloatArray*)&quant10_scale, (TfLiteIntArray*)&quant10_zero, 0 };
const TfLiteFullyConnectedParams opdata0 = { kTfLiteActRelu, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs0 = { 3, { 0,1,2 } };
const TfArray<1, int> outputs0 = { 1, { 7 } };
const TfLiteFullyConnectedParams opdata1 = { kTfLiteActRelu, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs1 = { 3, { 7,3,4 } };
const TfArray<1, int> outputs1 = { 1, { 8 } };
const TfLiteFullyConnectedParams opdata2 = { kTfLiteActNone, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs2 = { 3, { 8,5,6 } };
const TfArray<1, int> outputs2 = { 1, { 9 } };
const TfLiteSoftmaxParams opdata3 = { 1 };
const TfArray<1, int> inputs3 = { 1, { 9 } };
const TfArray<1, int> outputs3 = { 1, { 10 } };
const TensorInfo_t tensorData[] = {
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension0, 54, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant0))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data1, (TfLiteIntArray*)&tensor_dimension1, 1620, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant1))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data2, (TfLiteIntArray*)&tensor_dimension2, 120, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant2))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data3, (TfLiteIntArray*)&tensor_dimension3, 300, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant3))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data4, (TfLiteIntArray*)&tensor_dimension4, 40, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant4))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data5, (TfLiteIntArray*)&tensor_dimension5, 40, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant5))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data6, (TfLiteIntArray*)&tensor_dimension6, 16, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant6))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 64, (TfLiteIntArray*)&tensor_dimension7, 30, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant7))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension8, 10, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant8))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 16, (TfLiteIntArray*)&tensor_dimension9, 4, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant9))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension10, 4, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant10))}, },
};

const struct FullyConnectedNodeInfo_t node0 = {
  .inputs = (TfLiteIntArray*)&inputs0,
  .outputs = (TfLiteIntArray*)&outputs0,
  .params = &opdata0,
};
const struct FullyConnectedNodeInfo_t node1 = {
  .inputs = (TfLiteIntArray*)&inputs1,
  .outputs = (TfLiteIntArray*)&outputs1,
  .params = &opdata1,
};
const struct FullyConnectedNodeInfo_t node2 = {
  .inputs = (TfLiteIntArray*)&inputs2,
  .outputs = (TfLiteIntArray*)&outputs2,
  .params = &opdata2,
};
const struct SoftmaxNodeInfo_t node3 = {
  .inputs = (TfLiteIntArray*)&inputs3,
  .outputs = (TfLiteIntArray*)&outputs3,
  .params = &opdata3,
};

// references, these are actually allocated in the arena
OpDataFullyConnected* user_data0;
OpDataFullyConnected* user_data1;
OpDataFullyConnected* user_data2;
SoftmaxParams* user_data3;


static void init_tflite_tensor(size_t i, TfLiteTensor *tensor) {
  tensor->type = tensorData[i].type;
  tensor->is_variable = 0;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  tensor->allocation_type = tensorData[i].allocation_type;
#else
  tensor->allocation_type = (tensor_arena <= tensorData[i].data && tensorData[i].data < tensor_arena + kTensorArenaSize) ? kTfLiteArenaRw : kTfLiteMmapRo;
#endif
  tensor->bytes = tensorData[i].bytes;
  tensor->dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  if(tensor->allocation_type == kTfLiteArenaRw){
    uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

    tensor->data.data =  start;
  }
  else {
      tensor->data.data = tensorData[i].data;
  }
#else
  tensor->data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
  tensor->quantization = tensorData[i].quantization;
  if (tensor->quantization.type == kTfLiteAffineQuantization) {
    TfLiteAffineQuantization const* quant = ((TfLiteAffineQuantization const*)(tensorData[i].quantization.params));
    tensor->params.scale = quant->scale->data[0];
    tensor->params.zero_point = quant->zero_point->data[0];
  }
  if (tensor->allocation_type == kTfLiteArenaRw) {
    auto data_end_ptr = (uint8_t*)tensor->data.data + tensorData[i].bytes;
    if (data_end_ptr > tensor_boundary) {
      tensor_boundary = data_end_ptr;
    }
  }
}

static void init_tflite_eval_tensor(size_t i, TfLiteEvalTensor *tensor) {
  tensor->type = tensorData[i].type;

  tensor->dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  auto allocation_type = tensorData[i].allocation_type;
#else
  auto allocation_type = (tensor_arena <= tensorData[i].data && tensorData[i].data < tensor_arena + kTensorArenaSize) ? kTfLiteArenaRw : kTfLiteMmapRo;
#endif


#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  if(allocation_type == kTfLiteArenaRw){
    uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

    tensor->data.data =  start;
  }
  else {
      tensor->data.data = tensorData[i].data;
  }
#else
  tensor->data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
}

static void* overflow_buffers[EI_MAX_OVERFLOW_BUFFER_COUNT];
static size_t overflow_buffers_ix = 0;
static void * AllocatePersistentBuffer(struct TfLiteContext* ctx,
                                       size_t bytes) {
  void *ptr;
  if (current_location - bytes < tensor_boundary) {
    if (overflow_buffers_ix > EI_MAX_OVERFLOW_BUFFER_COUNT - 1) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d, does not fit in tensor arena and reached EI_MAX_OVERFLOW_BUFFER_COUNT\n",
        (int)bytes);
      return NULL;
    }

    // OK, this will look super weird, but.... we have CMSIS-NN buffers which
    // we cannot calculate beforehand easily.
    ptr = ei_calloc(bytes, 1);
    if (ptr == NULL) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d\n", (int)bytes);
      return NULL;
    }
    overflow_buffers[overflow_buffers_ix++] = ptr;
    return ptr;
  }

  current_location -= bytes;

  ptr = current_location;
  memset(ptr, 0, bytes);

  return ptr;
}
typedef struct {
  size_t bytes;
  void *ptr;
} scratch_buffer_t;
static scratch_buffer_t scratch_buffers[EI_MAX_SCRATCH_BUFFER_COUNT];
static size_t scratch_buffers_ix = 0;

static TfLiteStatus RequestScratchBufferInArena(struct TfLiteContext* ctx, size_t bytes,
                                                int* buffer_idx) {
  if (scratch_buffers_ix > EI_MAX_SCRATCH_BUFFER_COUNT - 1) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d, reached EI_MAX_SCRATCH_BUFFER_COUNT\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffer_t b;
  b.bytes = bytes;

  b.ptr = AllocatePersistentBuffer(ctx, b.bytes);
  if (!b.ptr) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffers[scratch_buffers_ix] = b;
  *buffer_idx = scratch_buffers_ix;

  scratch_buffers_ix++;

  return kTfLiteOk;
}

static void* GetScratchBuffer(struct TfLiteContext* ctx, int buffer_idx) {
  if (buffer_idx > (int)scratch_buffers_ix) {
    return NULL;
  }
  return scratch_buffers[buffer_idx].ptr;
}

static TfLiteTensor* GetTensor(const struct TfLiteContext* context,
                               int tensor_idx) {
  return nullptr;
}

static TfLiteEvalTensor* GetEvalTensor(const struct TfLiteContext* context,
                                       int tensor_idx) {
  return nullptr;
}

} // namespace

TfLiteStatus trained_model_init( void*(*alloc_fnc)(size_t,size_t) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  tensor_arena = (uint8_t*) alloc_fnc(16, kTensorArenaSize);
  if (!tensor_arena) {
    ei_printf("ERR: failed to allocate tensor arena\n");
    return kTfLiteError;
  }
#else
  memset(tensor_arena, 0, kTensorArenaSize);
#endif
  tensor_boundary = tensor_arena;
  current_location = tensor_arena + kTensorArenaSize;
  ctx.AllocatePersistentBuffer = &AllocatePersistentBuffer;
  ctx.RequestScratchBufferInArena = &RequestScratchBufferInArena;
  ctx.GetScratchBuffer = &GetScratchBuffer;
  ctx.GetTensor = &GetTensor;
  ctx.GetEvalTensor = &GetEvalTensor;
  ctx.tensors = nullptr;
  ctx.tensors_size = 11;
  if (tensor_boundary > current_location /* end of arena size */) {
    ei_printf("ERR: tensor arena is too small, does not fit model - even without scratch buffers\n");
    return kTfLiteError;
  }

  // init user data
  user_data0 = FullyConnectedInit(&ctx, nullptr, 0);
  user_data1 = FullyConnectedInit(&ctx, nullptr, 0);
  user_data2 = FullyConnectedInit(&ctx, nullptr, 0);
  user_data3 = TypedSoftmaxInit(&ctx, nullptr, 0);

  TfLiteStatus status;
  // node0
  {
    TfLiteTensor input;
    init_tflite_tensor(0, &input);
    TfLiteTensor bias;
    init_tflite_tensor(1, &bias);
    TfLiteTensor filter;
    init_tflite_tensor(2, &filter);
    TfLiteTensor output;
    init_tflite_tensor(7, &output);
    status = FullyConnectedPrepare(&ctx, (const TfLiteTensor*)&input,
      (const TfLiteTensor*)&bias,
      (const TfLiteTensor*)&filter,
      &output,
      user_data0,
      node0.params);
    if (status != kTfLiteOk) {
      return status;
    }
  }
  // node1
  {
    TfLiteTensor input;
    init_tflite_tensor(7, &input);
    TfLiteTensor bias;
    init_tflite_tensor(3, &bias);
    TfLiteTensor filter;
    init_tflite_tensor(4, &filter);
    TfLiteTensor output;
    init_tflite_tensor(8, &output);
    status = FullyConnectedPrepare(&ctx, (const TfLiteTensor*)&input,
      (const TfLiteTensor*)&bias,
      (const TfLiteTensor*)&filter,
      &output,
      user_data1,
      node1.params);
    if (status != kTfLiteOk) {
      return status;
    }
  }
  // node2
  {
    TfLiteTensor input;
    init_tflite_tensor(8, &input);
    TfLiteTensor bias;
    init_tflite_tensor(5, &bias);
    TfLiteTensor filter;
    init_tflite_tensor(6, &filter);
    TfLiteTensor output;
    init_tflite_tensor(9, &output);
    status = FullyConnectedPrepare(&ctx, (const TfLiteTensor*)&input,
      (const TfLiteTensor*)&bias,
      (const TfLiteTensor*)&filter,
      &output,
      user_data2,
      node2.params);
    if (status != kTfLiteOk) {
      return status;
    }
  }
  // node3
  {
    TfLiteTensor input;
    init_tflite_tensor(9, &input);
    TfLiteTensor output;
    init_tflite_tensor(10, &output);
    status = TypedSoftmaxPrepare(&ctx,
      (const TfLiteTensor*)&input,
      &output,
      user_data3,
      node3.params);
    if (status != kTfLiteOk) {
      return status;
    }
  }

  return kTfLiteOk;
}

static const int inTensorIndices[] = {
  0,
};
void trained_model_input(int index, TfLiteTensor *tensor) {
  init_tflite_tensor(inTensorIndices[index], tensor);
}

static const int outTensorIndices[] = {
  10,
};
void trained_model_output(int index, TfLiteTensor *tensor) {
  init_tflite_tensor(outTensorIndices[index], tensor);
}

TfLiteStatus trained_model_invoke() {
  TfLiteStatus status;
  // node0
  {
    TfLiteEvalTensor input;
    init_tflite_eval_tensor(0, &input);
    TfLiteEvalTensor bias;
    init_tflite_eval_tensor(1, &bias);
    TfLiteEvalTensor filter;
    init_tflite_eval_tensor(2, &filter);
    TfLiteEvalTensor output;
    init_tflite_eval_tensor(7, &output);
    status = FullyConnectedEval(&ctx,
      (const TfLiteEvalTensor*)&input,
      (const TfLiteEvalTensor*)&bias,
      (const TfLiteEvalTensor*)&filter,
      &output,
      user_data0,
      node0.params);
    if (status != kTfLiteOk) {
      return status;
    }
  }
  // node1
  {
    TfLiteEvalTensor input;
    init_tflite_eval_tensor(7, &input);
    TfLiteEvalTensor bias;
    init_tflite_eval_tensor(3, &bias);
    TfLiteEvalTensor filter;
    init_tflite_eval_tensor(4, &filter);
    TfLiteEvalTensor output;
    init_tflite_eval_tensor(8, &output);
    status = FullyConnectedEval(&ctx,
      (const TfLiteEvalTensor*)&input,
      (const TfLiteEvalTensor*)&bias,
      (const TfLiteEvalTensor*)&filter,
      &output,
      user_data1,
      node1.params);
    if (status != kTfLiteOk) {
      return status;
    }
  }
  // node2
  {
    TfLiteEvalTensor input;
    init_tflite_eval_tensor(8, &input);
    TfLiteEvalTensor bias;
    init_tflite_eval_tensor(5, &bias);
    TfLiteEvalTensor filter;
    init_tflite_eval_tensor(6, &filter);
    TfLiteEvalTensor output;
    init_tflite_eval_tensor(9, &output);
    status = FullyConnectedEval(&ctx,
      (const TfLiteEvalTensor*)&input,
      (const TfLiteEvalTensor*)&bias,
      (const TfLiteEvalTensor*)&filter,
      &output,
      user_data2,
      node2.params);
    if (status != kTfLiteOk) {
      return status;
    }
  }
  // node3
  {
    TfLiteEvalTensor input;
    init_tflite_eval_tensor(9, &input);
    TfLiteEvalTensor output;
    init_tflite_eval_tensor(10, &output);
    SoftmaxQuantizedEval(
      (const TfLiteEvalTensor*)&input,
      &output,
      *user_data3);
    status = kTfLiteOk;
    if (status != kTfLiteOk) {
      return status;
    }
  }
  return kTfLiteOk;
}

TfLiteStatus trained_model_reset( void (*free_fnc)(void* ptr) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  free_fnc(tensor_arena);
#endif

  // scratch buffers are allocated within the arena, so just reset the counter so memory can be reused
  scratch_buffers_ix = 0;

  // overflow buffers are on the heap, so free them first
  for (size_t ix = 0; ix < overflow_buffers_ix; ix++) {
    ei_free(overflow_buffers[ix]);
  }
  overflow_buffers_ix = 0;
  return kTfLiteOk;
}
